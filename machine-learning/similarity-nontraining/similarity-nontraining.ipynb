{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ff16e4b-3149-4f86-b290-79de54b90783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dot, Lambda, Embedding, TextVectorization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils import data_merger, filter_data\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "933992a5-a7f0-49b0-aee9-84aa08661e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('./dataset.xlsx')\n",
    "df = pd.DataFrame(data)\n",
    "listAnswers = data_merger([df['a1'],df['a2'],df['a3'],df['a4'],df['a5'],df['a6'],df['a7'],df['a8'],df['a9'],df['a10'],df['a11'],df['a12'],df['a13'],df['a14'],df['a15'],df['a16'],df['a17'],df['a18'],df['a19'],df['a20']])\n",
    "combinedAnswers = []\n",
    "for i in range(len(listAnswers)):\n",
    "    for item in listAnswers[i]:\n",
    "        combinedAnswers.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aa8d81-f6a4-40ce-95eb-6c1a50c41993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# items = []\n",
    "# index = 1\n",
    "# for i in range(0, 110):\n",
    "#     if i%10 == 0 and i != 0:\n",
    "#         index += 1\n",
    "#     if index == 11 :\n",
    "#         index = 1\n",
    "#     for j in range(len(listAnswers[i])):\n",
    "#         items.append(f\"({index+5}, '\"+listAnswers[i][j]+\"'),\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c14c6b7-ecc4-4014-8593-a49375c7067a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(listAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85c23b5f-1606-4522-a641-419637075447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20018418-2997-4de4-b76d-e6380ee80f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(combinedAnswers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de7227c-1ed2-4c45-a3dd-06d344743dc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert sentences to sequences and pad them\n",
    "sequences = tokenizer.texts_to_sequences(combinedAnswers)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f298857-ca6f-4c3e-920b-7684416bc115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert sentences to TF-IDF vectors using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer().fit(combinedAnswers)\n",
    "vectors = vectorizer.transform(combinedAnswers).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c371fc90-5c12-4e2e-b990-4411a7bd2ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_a = Input(shape=(len(padded_sequences[0]),))\n",
    "input_b = Input(shape=(len(padded_sequences[0]),))\n",
    "\n",
    "flatten_a = Flatten()(input_a)\n",
    "flatten_b = Flatten()(input_b)\n",
    "\n",
    "cosine_similarity = Lambda(lambda x: tf.reduce_sum(tf.multiply(x[0], x[1]), axis=-1) / \n",
    "                            (tf.norm(x[0], axis=-1) * tf.norm(x[1], axis=-1)), \n",
    "                            output_shape=lambda _: (1,))([flatten_a, flatten_b])\n",
    "\n",
    "model = Model(inputs=[input_a, input_b], outputs=cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b6931e6-832e-4dff-a913-fdf43116e68d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4237d026-80b2-42e1-b922-60c2712a8ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_similarity(strA, strB):\n",
    "    seqA = tokenizer.texts_to_sequences([strA])\n",
    "    seqB = tokenizer.texts_to_sequences([strB])\n",
    "\n",
    "    # Pad sequences\n",
    "    padded_seqA = pad_sequences(seqA, padding='post', maxlen=len(padded_sequences[0]))\n",
    "    padded_seqB = pad_sequences(seqB, padding='post', maxlen=len(padded_sequences[0]))\n",
    "\n",
    "    # Predict similarity using model.predict\n",
    "    similarity = model.predict([padded_seqA, padded_seqB])[0]\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e0f32d-b1f2-444d-ad70-37fba22e0440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 62ms/step\n",
      "Similarity Score: 0.6474320292472839\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "sentence_a = \"Menurut saya, kurangnyangan anggaran yang terbatas, yang dapat memengaruhi kualitas pendidikan yang mereka tawarkan.\"\n",
    "sentence_b = \"Menurut saya, kurangnyangan anggaran yang terbatas, yang \"\n",
    "\n",
    "similarity_score = predict_similarity(sentence_a, sentence_b)\n",
    "print(f\"Similarity Score: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "448ddb6d-5ce9-432b-9b13-2a54fff1d064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('similarity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8431940-6ab8-43c0-a78e-d95c431cac34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeec96b-234d-4402-b806-5cc9a2eff102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83153d-f99a-4079-9d20-19eb5339a260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b4b3d2-48ee-49e9-a032-04c498e74bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd971d12-09cc-43a9-932b-26297e4bfcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92076478-d4d9-44d4-aa78-5c5fd9ef707d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0054fd-a397-401d-bd78-cf4f16182883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
